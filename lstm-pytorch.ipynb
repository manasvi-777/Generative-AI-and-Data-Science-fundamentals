{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# ---------------------\n# 1. Activation Functions\n# ---------------------\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef tanh(x):\n    return np.tanh(x)\n\n# ---------------------\n# 2. LSTM Cell Implementation\n# ---------------------\nclass LSTMCell:\n    def __init__(self, input_size, hidden_size):\n        # Combined parameters for all gates (forget, input, cell, output)\n        self.W = np.random.randn(4 * hidden_size, input_size + hidden_size) * 0.01  # <- Fix here\n        self.b = np.zeros((4 * hidden_size, 1))\n        \n        # Split weights into components for each gate\n        self.W_f = self.W[:hidden_size]          # Forget gate\n        self.W_i = self.W[hidden_size:2*hidden_size]  # Input gate\n        self.W_c = self.W[2*hidden_size:3*hidden_size]  # Cell candidate\n        self.W_o = self.W[3*hidden_size:]        # Output gate\n        \n        self.hidden_size = hidden_size\n\n\n    def forward(self, x, h_prev, c_prev):\n        \"\"\"\n        x: input vector (input_size, 1)\n        h_prev: previous hidden state (hidden_size, 1)\n        c_prev: previous cell state (hidden_size, 1)\n        \"\"\"\n        # 1. Concatenate input and previous hidden state\n        combined = np.vstack((h_prev, x))  # (hidden_size + input_size, 1)\n\n        # 2. Compute all gates simultaneously\n        gates = self.W @ combined + self.b\n        \n        # 3. Split into individual gates\n        f = sigmoid(gates[:self.hidden_size])          # Forget gate\n        i = sigmoid(gates[self.hidden_size:2*self.hidden_size])  # Input gate\n        c_candidate = tanh(gates[2*self.hidden_size:3*self.hidden_size])  # Cell candidate\n        o = sigmoid(gates[3*self.hidden_size:])        # Output gate\n\n        # 4. Update cell state\n        c_next = f * c_prev + i * c_candidate\n\n        # 5. Compute new hidden state\n        h_next = o * tanh(c_next)\n\n        return h_next, c_next\n\n# ---------------------\n# 3. Usage Example\n# ---------------------\n# Hyperparameters\ninput_size = 3\nhidden_size = 2\nseq_length = 4\n\n# Initialize LSTM cell\nlstm = LSTMCell(input_size, hidden_size)\n\n# Initialize hidden and cell states\nh = np.zeros((hidden_size, 1))\nc = np.zeros((hidden_size, 1))\n\n# Sample input sequence (seq_length, input_size, 1)\ninputs = [np.random.randn(input_size, 1) for _ in range(seq_length)]\n\n# Forward pass through time\nprint(\"Step-by-Step LSTM Processing:\")\nfor t in range(seq_length):\n    h, c = lstm.forward(inputs[t], h, c)\n    print(f\"Time Step {t+1}:\")\n    print(f\"Hidden State:\\n{h.round(4)}\")\n    print(f\"Cell State:\\n{c.round(4)}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T05:44:48.988421Z","iopub.execute_input":"2025-05-26T05:44:48.988777Z","iopub.status.idle":"2025-05-26T05:44:49.010166Z","shell.execute_reply.started":"2025-05-26T05:44:48.988750Z","shell.execute_reply":"2025-05-26T05:44:49.008792Z"}},"outputs":[{"name":"stdout","text":"Step-by-Step LSTM Processing:\nTime Step 1:\nHidden State:\n[[0.0027]\n [0.0004]]\nCell State:\n[[0.0053]\n [0.0008]]\n\nTime Step 2:\nHidden State:\n[[0.0063]\n [0.0007]]\nCell State:\n[[0.0124]\n [0.0014]]\n\nTime Step 3:\nHidden State:\n[[ 0.0113]\n [-0.0006]]\nCell State:\n[[ 0.0224]\n [-0.0012]]\n\nTime Step 4:\nHidden State:\n[[0.0067]\n [0.0001]]\nCell State:\n[[0.0134]\n [0.0003]]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef tanh(x):\n    return np.tanh(x)\n\nclass LSTMCell:\n    def __init__(self, input_size, hidden_size):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        \n        # Weight matrices for gates: dimensions (hidden_size, hidden_size + input_size)\n        self.W_f = np.random.randn(hidden_size, hidden_size + input_size) * 0.1\n        self.b_f = np.zeros((hidden_size, 1))\n        \n        self.W_i = np.random.randn(hidden_size, hidden_size + input_size) * 0.1\n        self.b_i = np.zeros((hidden_size, 1))\n        \n        self.W_C = np.random.randn(hidden_size, hidden_size + input_size) * 0.1\n        self.b_C = np.zeros((hidden_size, 1))\n        \n        self.W_o = np.random.randn(hidden_size, hidden_size + input_size) * 0.1\n        self.b_o = np.zeros((hidden_size, 1))\n\n    def forward(self, x_t, h_prev, C_prev):\n        # x_t shape: (input_size, 1)\n        # h_prev shape: (hidden_size, 1)\n        # C_prev shape: (hidden_size, 1)\n        \n        # Concatenate h_prev and x_t\n        concat = np.vstack((h_prev, x_t))  # shape: (hidden_size + input_size, 1)\n        \n        # Forget gate\n        f_t = sigmoid(np.dot(self.W_f, concat) + self.b_f)\n        \n        # Input gate\n        i_t = sigmoid(np.dot(self.W_i, concat) + self.b_i)\n        C_tilde = tanh(np.dot(self.W_C, concat) + self.b_C)\n        \n        # Update cell state\n        C_t = f_t * C_prev + i_t * C_tilde\n        \n        # Output gate\n        o_t = sigmoid(np.dot(self.W_o, concat) + self.b_o)\n        h_t = o_t * tanh(C_t)\n        \n        return h_t, C_t\n\n# Example usage:\n\ninput_size = 3\nhidden_size = 2\n\nlstm_cell = LSTMCell(input_size, hidden_size)\n\n# Random initial hidden state and cell state\nh_prev = np.zeros((hidden_size, 1))\nC_prev = np.zeros((hidden_size, 1))\n\n# Random input vector\nx_t = np.random.randn(input_size, 1)\n\nh_next, C_next = lstm_cell.forward(x_t, h_prev, C_prev)\n\nprint(\"Next hidden state (h_t):\\n\", h_next)\nprint(\"Next cell state (C_t):\\n\", C_next)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-26T07:31:35.978Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PYTORCH IMPLEMENTATION TO SHOW THE WORKING OF ALL INTERMEDIATE STATES","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass LSTMCellExplained(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(LSTMCellExplained, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n        # One linear layer for all 4 gates: i, f, g, o\n        self.W = nn.Linear(input_size + hidden_size, 4 * hidden_size)\n\n    def forward(self, x_t, h_prev, c_prev):\n        # Concatenate input and previous hidden state\n        combined = torch.cat((x_t, h_prev), dim=1)  # Shape: [batch_size, input_size + hidden_size]\n\n        # Compute all gate values\n        gates = self.W(combined)  # Shape: [batch_size, 4 * hidden_size]\n\n        # Split into individual gates\n        i_t, f_t, g_t, o_t = gates.chunk(4, dim=1)\n\n        # Apply nonlinearities\n        i_t = torch.sigmoid(i_t)  # Input gate\n        f_t = torch.sigmoid(f_t)  # Forget gate\n        g_t = torch.tanh(g_t)     # Cell candidate\n        o_t = torch.sigmoid(o_t)  # Output gate\n\n        # Update cell and hidden state\n        c_t = f_t * c_prev + i_t * g_t\n        h_t = o_t * torch.tanh(c_t)\n\n        # Print dimensions of all components\n        print(\"🔍 Dimensions:\")\n        print(\"Input x_t:\", x_t.shape)\n        print(\"Hidden state h_prev:\", h_prev.shape)\n        print(\"Cell state c_prev:\", c_prev.shape)\n        print(\"Combined [x_t, h_prev]:\", combined.shape)\n        print(\"All gates (linear output):\", gates.shape)\n        print(\"Input gate i_t:\", i_t.shape)\n        print(\"Forget gate f_t:\", f_t.shape)\n        print(\"Cell candidate g_t:\", g_t.shape)\n        print(\"Output gate o_t:\", o_t.shape)\n        print(\"New cell state c_t:\", c_t.shape)\n        print(\"New hidden state h_t:\", h_t.shape)\n\n        return h_t, c_t, {\n            'input_gate': i_t,\n            'forget_gate': f_t,\n            'cell_candidate': g_t,\n            'output_gate': o_t,\n            'hidden_state': h_t,\n            'cell_state': c_t\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T12:13:05.132730Z","iopub.execute_input":"2025-05-26T12:13:05.133047Z","iopub.status.idle":"2025-05-26T12:13:11.456817Z","shell.execute_reply.started":"2025-05-26T12:13:05.133016Z","shell.execute_reply":"2025-05-26T12:13:11.455861Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Parameters\ninput_size = 3\nhidden_size = 4\nbatch_size = 1\n\n# Model\nlstm_cell = LSTMCellExplained(input_size, hidden_size)\n\n# Input and initial states\nx_t = torch.randn(batch_size, input_size)\nh_prev = torch.zeros(batch_size, hidden_size)\nc_prev = torch.zeros(batch_size, hidden_size)\n\n# Forward pass\nh_t, c_t, gates = lstm_cell(x_t, h_prev, c_prev)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T12:13:32.842257Z","iopub.execute_input":"2025-05-26T12:13:32.842599Z","iopub.status.idle":"2025-05-26T12:13:33.002964Z","shell.execute_reply.started":"2025-05-26T12:13:32.842574Z","shell.execute_reply":"2025-05-26T12:13:33.002121Z"}},"outputs":[{"name":"stdout","text":"🔍 Dimensions:\nInput x_t: torch.Size([1, 3])\nHidden state h_prev: torch.Size([1, 4])\nCell state c_prev: torch.Size([1, 4])\nCombined [x_t, h_prev]: torch.Size([1, 7])\nAll gates (linear output): torch.Size([1, 16])\nInput gate i_t: torch.Size([1, 4])\nForget gate f_t: torch.Size([1, 4])\nCell candidate g_t: torch.Size([1, 4])\nOutput gate o_t: torch.Size([1, 4])\nNew cell state c_t: torch.Size([1, 4])\nNew hidden state h_t: torch.Size([1, 4])\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom collections import Counter\nimport string\n\nclass LSTMTextGenerator(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout=0.3):\n        super(LSTMTextGenerator, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        # Embedding layer: converts token indices to dense vectors\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        \n        # LSTM layer : processes embeddings and learns sequential patterns\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n                           dropout=dropout, batch_first=True)\n        \n        # Dropout for regularization\n        self.dropout = nn.Dropout(dropout)\n        \n        # Output layer: maps hidden states to vocabulary probabilities\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n        \n    def forward(self, x, hidden=None, verbose=False):\n        \"\"\"\n        Forward pass with detailed dimension tracking\n        \n        Args:\n            x: Input tensor of token indices [batch_size, sequence_length]\n            hidden: Initial hidden state (optional)\n            verbose: Print intermediate dimensions\n        \"\"\"\n        batch_size, seq_len = x.shape\n        \n        if verbose:\n            print(f\"Input dimensions: {x.shape} [batch_size={batch_size}, seq_len={seq_len}]\")\n        \n        # Step 1: Embedding lookup\n        # Input: [batch_size, seq_len] -> Output: [batch_size, seq_len, embedding_dim]\n        embedded = self.embedding(x)\n        \n        if verbose:\n            print(f\"After embedding: {embedded.shape} [batch_size, seq_len, embedding_dim]\")\n            print(f\"Embedding weights shape: {self.embedding.weight.shape} [vocab_size, embedding_dim]\")\n        \n        # Step 2: LSTM processing\n        # Input: [batch_size, seq_len, embedding_dim]\n        # Output: [batch_size, seq_len, hidden_dim], (h_n, c_n)\n        if hidden is None:\n            lstm_out, (h_n, c_n) = self.lstm(embedded)\n        else:\n            lstm_out, (h_n, c_n) = self.lstm(embedded, hidden)\n        \n        if verbose:\n            print(f\"LSTM output: {lstm_out.shape} [batch_size, seq_len, hidden_dim]\")\n            print(f\"Final hidden state (h_n): {h_n.shape} [num_layers, batch_size, hidden_dim]\")\n            print(f\"Final cell state (c_n): {c_n.shape} [num_layers, batch_size, hidden_dim]\")\n        \n        # Step 3: Apply dropout\n        lstm_out = self.dropout(lstm_out)\n        \n        # Step 4: Project to vocabulary size\n        # Reshape: [batch_size, seq_len, hidden_dim] -> [batch_size * seq_len, hidden_dim]\n        lstm_out_reshaped = lstm_out.reshape(-1, self.hidden_dim)\n        \n        if verbose:\n            print(f\"Reshaped for FC: {lstm_out_reshaped.shape} [batch_size*seq_len, hidden_dim]\")\n        \n        # Linear layer: [batch_size * seq_len, hidden_dim] -> [batch_size * seq_len, vocab_size]\n        output = self.fc(lstm_out_reshaped)\n        \n        if verbose:\n            print(f\"FC output: {output.shape} [batch_size*seq_len, vocab_size]\")\n        \n        # Reshape back: [batch_size * seq_len, vocab_size] -> [batch_size, seq_len, vocab_size]\n        output = output.reshape(batch_size, seq_len, self.vocab_size)\n        \n        if verbose:\n            print(f\"Final output: {output.shape} [batch_size, seq_len, vocab_size]\")\n        \n        return output, (h_n, c_n)\n    \n    def init_hidden(self, batch_size, device):\n        \"\"\"Initialize hidden and cell states\"\"\"\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n        return (h0, c0)\n\nclass TextPreprocessor:\n    def __init__(self):\n        self.char_to_idx = {}\n        self.idx_to_char = {}\n        self.vocab_size = 0\n    \n    def fit(self, text):\n        \"\"\"Build vocabulary from text\"\"\"\n        chars = sorted(list(set(text)))\n        self.vocab_size = len(chars)\n        \n        self.char_to_idx = {ch: i for i, ch in enumerate(chars)}\n        self.idx_to_char = {i: ch for i, ch in enumerate(chars)}\n        \n        print(f\"Vocabulary size: {self.vocab_size}\")\n        print(f\"Characters: {chars}\")\n    \n    def encode(self, text):\n        \"\"\"Convert text to indices\"\"\"\n        return [self.char_to_idx[char] for char in text]\n    \n    def decode(self, indices):\n        \"\"\"Convert indices to text\"\"\"\n        return ''.join([self.idx_to_char[idx] for idx in indices])\n\ndef create_sequences(data, seq_length):\n    \"\"\"Create input-target pairs for training\"\"\"\n    sequences = []\n    targets = []\n    \n    for i in range(len(data) - seq_length):\n        seq = data[i:i + seq_length]\n        target = data[i + 1:i + seq_length + 1]\n        sequences.append(seq)\n        targets.append(target)\n    \n    return sequences, targets\n\ndef demonstrate_embeddings_and_processing():\n    \"\"\"Demonstrate the complete pipeline with dimension tracking\"\"\"\n    \n    # Sample text data\n    text = \"hello world this is a simple example for lstm text generation\"\n    \n    # Preprocessing\n    preprocessor = TextPreprocessor()\n    preprocessor.fit(text)\n    encoded_text = preprocessor.encode(text)\n    \n    print(\"=\"*60)\n    print(\"TEXT PREPROCESSING\")\n    print(\"=\"*60)\n    print(f\"Original text: '{text}'\")\n    print(f\"Encoded text: {encoded_text}\")\n    print(f\"Vocabulary mapping: {preprocessor.char_to_idx}\")\n    \n    # Create sequences\n    seq_length = 10\n    sequences, targets = create_sequences(encoded_text, seq_length)\n    \n    # Convert to tensors\n    X = torch.tensor(sequences[:5])  # Take first 5 sequences for demo\n    y = torch.tensor(targets[:5])\n    \n    print(f\"\\nSequence shape: {X.shape}\")\n    print(f\"Target shape: {y.shape}\")\n    \n    # Model parameters\n    vocab_size = preprocessor.vocab_size\n    embedding_dim = 16\n    hidden_dim = 32\n    num_layers = 2\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"MODEL ARCHITECTURE\")\n    print(\"=\"*60)\n    print(f\"Vocabulary size: {vocab_size}\")\n    print(f\"Embedding dimension: {embedding_dim}\")\n    print(f\"Hidden dimension: {hidden_dim}\")\n    print(f\"Number of LSTM layers: {num_layers}\")\n    \n    # Create model\n    model = LSTMTextGenerator(vocab_size, embedding_dim, hidden_dim, num_layers)\n    \n    print(f\"\\nModel parameters:\")\n    for name, param in model.named_parameters():\n        print(f\"  {name}: {param.shape}\")\n    \n    # Forward pass with verbose output\n    print(\"\\n\" + \"=\"*60)\n    print(\"FORWARD PASS WITH DIMENSION TRACKING\")\n    print(\"=\"*60)\n    \n    model.eval()\n    with torch.no_grad():\n        output, (h_n, c_n) = model(X, verbose=True)\n    \n    # Show embedding details\n    print(\"\\n\" + \"=\"*60)\n    print(\"EMBEDDING LAYER DETAILS\")\n    print(\"=\"*60)\n    \n    sample_input = X[0:1, :3]  # First sequence, first 3 tokens\n    print(f\"Sample input tokens: {sample_input.squeeze().tolist()}\")\n    print(f\"Corresponding characters: '{preprocessor.decode(sample_input.squeeze().tolist())}'\")\n    \n    sample_embeddings = model.embedding(sample_input)\n    print(f\"Sample embeddings shape: {sample_embeddings.shape}\")\n    print(f\"First token embedding:\\n{sample_embeddings[0, 0, :].detach().numpy()}\")\n    \n    # Show LSTM state evolution\n    print(\"\\n\" + \"=\"*60)\n    print(\"LSTM STATE EVOLUTION\")\n    print(\"=\"*60)\n    \n    # Process one token at a time to show state evolution\n    single_input = X[0:1, :1]  # First token of first sequence\n    hidden = model.init_hidden(1, X.device)\n    \n    print(\"Processing tokens one by one:\")\n    for i in range(min(5, X.shape[1])):\n        token = X[0:1, i:i+1]\n        char = preprocessor.idx_to_char[token.item()]\n        \n        with torch.no_grad():\n            _, (h_n, c_n) = model(token, hidden)\n        \n        print(f\"Token {i}: '{char}' (idx: {token.item()})\")\n        print(f\"  Hidden state norm: {torch.norm(h_n).item():.4f}\")\n        print(f\"  Cell state norm: {torch.norm(c_n).item():.4f}\")\n        \n        hidden = (h_n, c_n)\n\ndef generate_text(model, preprocessor, seed_text, length=50, temperature=1.0):\n    \"\"\"Generate text using the trained model\"\"\"\n    model.eval()\n    \n    # Encode seed text\n    current_seq = preprocessor.encode(seed_text)\n    generated = current_seq.copy()\n    \n    # Initialize hidden state\n    hidden = model.init_hidden(1, next(model.parameters()).device)\n    \n    with torch.no_grad():\n        for _ in range(length):\n            # Convert to tensor\n            x = torch.tensor([current_seq]).long()\n            \n            # Forward pass\n            output, hidden = model(x, hidden)\n            \n            # Get probabilities for the last token\n            probs = F.softmax(output[0, -1] / temperature, dim=0)\n            \n            # Sample next token\n            next_token = torch.multinomial(probs, 1).item()\n            \n            # Update sequences\n            generated.append(next_token)\n            current_seq = current_seq[1:] + [next_token]  # Sliding window\n    \n    return preprocessor.decode(generated)\n\n# Run the demonstration\nif __name__ == \"__main__\":\n    print(\"LSTM TEXT GENERATION WITH EMBEDDINGS AND DIMENSION TRACKING\")\n    print(\"=\"*80)\n    \n    demonstrate_embeddings_and_processing()\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING EXAMPLE\")\n    print(\"=\"*60)\n    \n    # Simple training example\n    text = \"hello world \" * 20  # Repeat for more data\n    preprocessor = TextPreprocessor()\n    preprocessor.fit(text)\n    encoded_text = preprocessor.encode(text)\n    \n    sequences, targets = create_sequences(encoded_text, 10)\n    X_train = torch.tensor(sequences)\n    y_train = torch.tensor(targets)\n    \n    model = LSTMTextGenerator(preprocessor.vocab_size, 16, 32, 2)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    \n    print(\"Training for 50 epochs...\")\n    model.train()\n    for epoch in range(50):\n        optimizer.zero_grad()\n        \n        output, _ = model(X_train)\n        loss = criterion(output.reshape(-1, preprocessor.vocab_size), \n                        y_train.reshape(-1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n    \n    # Generate some text\n    print(\"\\nGenerated text:\")\n    generated = generate_text(model, preprocessor, \"hello\", 30)\n    print(f\"'{generated}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-26T12:23:42.194324Z","iopub.execute_input":"2025-05-26T12:23:42.195053Z","iopub.status.idle":"2025-05-26T12:23:46.998289Z","shell.execute_reply.started":"2025-05-26T12:23:42.195023Z","shell.execute_reply":"2025-05-26T12:23:46.997432Z"}},"outputs":[{"name":"stdout","text":"LSTM TEXT GENERATION WITH EMBEDDINGS AND DIMENSION TRACKING\n================================================================================\nVocabulary size: 18\nCharacters: [' ', 'a', 'd', 'e', 'f', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'w', 'x']\n============================================================\nTEXT PREPROCESSING\n============================================================\nOriginal text: 'hello world this is a simple example for lstm text generation'\nEncoded text: [6, 3, 8, 8, 11, 0, 16, 11, 13, 8, 2, 0, 15, 6, 7, 14, 0, 7, 14, 0, 1, 0, 14, 7, 9, 12, 8, 3, 0, 3, 17, 1, 9, 12, 8, 3, 0, 4, 11, 13, 0, 8, 14, 15, 9, 0, 15, 3, 17, 15, 0, 5, 3, 10, 3, 13, 1, 15, 7, 11, 10]\nVocabulary mapping: {' ': 0, 'a': 1, 'd': 2, 'e': 3, 'f': 4, 'g': 5, 'h': 6, 'i': 7, 'l': 8, 'm': 9, 'n': 10, 'o': 11, 'p': 12, 'r': 13, 's': 14, 't': 15, 'w': 16, 'x': 17}\n\nSequence shape: torch.Size([5, 10])\nTarget shape: torch.Size([5, 10])\n\n============================================================\nMODEL ARCHITECTURE\n============================================================\nVocabulary size: 18\nEmbedding dimension: 16\nHidden dimension: 32\nNumber of LSTM layers: 2\n\nModel parameters:\n  embedding.weight: torch.Size([18, 16])\n  lstm.weight_ih_l0: torch.Size([128, 16])\n  lstm.weight_hh_l0: torch.Size([128, 32])\n  lstm.bias_ih_l0: torch.Size([128])\n  lstm.bias_hh_l0: torch.Size([128])\n  lstm.weight_ih_l1: torch.Size([128, 32])\n  lstm.weight_hh_l1: torch.Size([128, 32])\n  lstm.bias_ih_l1: torch.Size([128])\n  lstm.bias_hh_l1: torch.Size([128])\n  fc.weight: torch.Size([18, 32])\n  fc.bias: torch.Size([18])\n\n============================================================\nFORWARD PASS WITH DIMENSION TRACKING\n============================================================\nInput dimensions: torch.Size([5, 10]) [batch_size=5, seq_len=10]\nAfter embedding: torch.Size([5, 10, 16]) [batch_size, seq_len, embedding_dim]\nEmbedding weights shape: torch.Size([18, 16]) [vocab_size, embedding_dim]\nLSTM output: torch.Size([5, 10, 32]) [batch_size, seq_len, hidden_dim]\nFinal hidden state (h_n): torch.Size([2, 5, 32]) [num_layers, batch_size, hidden_dim]\nFinal cell state (c_n): torch.Size([2, 5, 32]) [num_layers, batch_size, hidden_dim]\nReshaped for FC: torch.Size([50, 32]) [batch_size*seq_len, hidden_dim]\nFC output: torch.Size([50, 18]) [batch_size*seq_len, vocab_size]\nFinal output: torch.Size([5, 10, 18]) [batch_size, seq_len, vocab_size]\n\n============================================================\nEMBEDDING LAYER DETAILS\n============================================================\nSample input tokens: [6, 3, 8]\nCorresponding characters: 'hel'\nSample embeddings shape: torch.Size([1, 3, 16])\nFirst token embedding:\n[ 0.47343692  0.08184347  0.21759345  0.94085073 -2.8865836  -0.26949227\n  0.8901447   0.13094072  0.08165459  0.7959773  -0.5114167  -0.7843105\n  1.611062   -0.32898268 -0.60725343  0.61552626]\n\n============================================================\nLSTM STATE EVOLUTION\n============================================================\nProcessing tokens one by one:\nToken 0: 'h' (idx: 6)\n  Hidden state norm: 0.5671\n  Cell state norm: 1.1777\nToken 1: 'e' (idx: 3)\n  Hidden state norm: 0.7312\n  Cell state norm: 1.4860\nToken 2: 'l' (idx: 8)\n  Hidden state norm: 0.8428\n  Cell state norm: 1.6634\nToken 3: 'l' (idx: 8)\n  Hidden state norm: 1.0124\n  Cell state norm: 2.0534\nToken 4: 'o' (idx: 11)\n  Hidden state norm: 0.8057\n  Cell state norm: 1.7060\n\n============================================================\nTRAINING EXAMPLE\n============================================================\nVocabulary size: 8\nCharacters: [' ', 'd', 'e', 'h', 'l', 'o', 'r', 'w']\nTraining for 50 epochs...\nEpoch 10, Loss: 1.6189\nEpoch 20, Loss: 0.7788\nEpoch 30, Loss: 0.2839\nEpoch 40, Loss: 0.1285\nEpoch 50, Loss: 0.0966\n\nGenerated text:\n'hello world hello world hello world'\n","output_type":"stream"}],"execution_count":4}]}